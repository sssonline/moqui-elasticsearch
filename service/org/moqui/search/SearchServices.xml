<?xml version="1.0" encoding="UTF-8"?>
<!--
This software is in the public domain under CC0 1.0 Universal plus a
Grant of Patent License.

To the extent possible under law, the author(s) have dedicated all
copyright and related and neighboring rights to this software to the
public domain worldwide. This software is distributed without any
warranty.

You should have received a copy of the CC0 Public Domain Dedication
along with this software (see the LICENSE.md file). If not, see
<http://creativecommons.org/publicdomain/zero/1.0/>.
-->
<services xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://moqui.org/xsd/service-definition-2.1.xsd">

    <service verb="index" noun="DataDocuments" authenticate="false" transaction-timeout="3600">
        <description>Indexes documents passed using ElasticSearch. The DataDocument must have an indexName.</description>
        <implements service="org.moqui.EntityServices.receive#DataFeed"/>
        <in-parameters>
            <parameter name="dataFeedId" required="false"/>
            <parameter name="feedStamp" type="Timestamp" required="false"/>
            <parameter name="getOriginalDocuments" type="Boolean" default="false"/>
            <parameter name="verifyIndexes" type="Boolean" default="true"/>
        </in-parameters>
        <out-parameters>
            <parameter name="documentVersionList" type="List" required="true"/>
            <parameter name="originalDocumentList" type="List" required="false"/>
        </out-parameters>
        <actions><script><![CDATA[
            import org.elasticsearch.action.bulk.BulkItemResponse
            import org.elasticsearch.action.bulk.BulkRequestBuilder
            import org.elasticsearch.action.bulk.BulkRequest
            import org.elasticsearch.action.bulk.BulkResponse
            import org.elasticsearch.action.get.GetRequest
            import org.elasticsearch.action.get.GetResponse
            import org.elasticsearch.action.index.IndexRequest
            import org.elasticsearch.action.index.IndexResponse

            import org.slf4j.Logger
            import org.slf4j.LoggerFactory
            import org.moqui.context.ExecutionContext
            import org.moqui.elasticsearch.ElasticSearchUtil
            import org.moqui.elasticsearch.EsClient

            int docsPerBulk = 1000

            ExecutionContext ec = context.ec
            EsClient esClient = ec.getTool("ElasticSearch", EsClient.class)
            Logger logger = LoggerFactory.getLogger("org.moqui.search.SearchServices.indexDataDocuments")

            // Make sure all indices exist
            if (verifyIndexes) {
                Set indexNames = new HashSet(documentList*._index)
                for (String indexName in indexNames) esClient.checkCreateIndex(indexName)
                Set dataDocumentIds = new HashSet(documentList*._type)
                for (String dataDocumentId in dataDocumentIds) esClient.checkCreateDocIndex(dataDocumentId)
            }

            documentVersionList = []
            originalDocumentList = getOriginalDocuments ? [] : null
            BulkRequest bulkRequest = new BulkRequest()
            int curBulkDocs = 0
            for (Map document in documentList) {
                // logger.warn("====== Indexing document: ${document}")

                String _index = document._index
                String _type = document._type
                String _id = document._id
                // String _timestamp = document._timestamp
                // As of ES 2.0 _index, _type, _id, and _timestamp shouldn't be in document to be indexed
                // clone document before removing fields so they are present for other code using the same data
                document = new LinkedHashMap(document)
                document.remove('_index'); document.remove('_type'); document.remove('_id'); document.remove('_timestamp')

                // to better separate very different documents and prepare for ES6 the index name for ES is the dataDocumentId (_type) lower cased
                String esIndexName = ElasticSearchUtil.ddIdToEsIndex(_type)

                if (getOriginalDocuments) {
                    // this may fail for a number of reasons, like index doesn't exist yet, so catch the exception
                    try {
                        GetResponse gr = esClient.get(new GetRequest(esIndexName, _type, _id))
                        Map originalDocument = gr.getSourceAsMap()
                        if (originalDocument != null) {
                            // As of ES 2.0 _index, _type, _id aren't included in the document
                            originalDocument._index = gr.getIndex()
                            originalDocument._type = gr.getType()
                            originalDocument._id = gr.getId()
                            originalDocument._version = gr.getVersion()
                            originalDocumentList.add(originalDocument)
                        } else {
                            originalDocumentList.add([:])
                        }
                    } catch (Exception e) {
                        logger.info("Could not get original document for [${_index}, ${_type}, ${_id}]: ${e.toString()}")
                        originalDocumentList.add([:])
                    }
                }

                // before indexing convert types needed for ES
                ElasticSearchUtil.convertTypesForEs(document)
                // add the document to the bulk index
                bulkRequest.add(new IndexRequest(esIndexName, _type, _id).source(document))
                // .setIndex(esIndexName).setType(_type).setId(_id)
                curBulkDocs++

                if (curBulkDocs >= docsPerBulk) {
                    BulkResponse bulkResponse = esClient.bulk(bulkRequest)
                    if (bulkResponse.hasFailures()) {
                        ec.message.addError(bulkResponse.buildFailureMessage())
                        break
                    }

                    BulkItemResponse[] itemResponses = bulkResponse.getItems()
                    int itemResponsesSize = itemResponses.length
                    for (int i = 0; i < itemResponsesSize; i++) documentVersionList.add(itemResponses[i].getVersion())

                    // create a new bulk builder for the next set
                    curBulkDocs = 0
                    bulkRequest = new BulkRequest()
                }
            }
            if (curBulkDocs > 0) {
                BulkResponse bulkResponse = esClient.bulk(bulkRequest)
                if (bulkResponse.hasFailures()) ec.message.addError(bulkResponse.buildFailureMessage())

                BulkItemResponse[] itemResponses = bulkResponse.getItems()
                int itemResponsesSize = itemResponses.length
                for (int i = 0; i < itemResponsesSize; i++) documentVersionList.add(itemResponses[i].getVersion())
            }
        ]]></script></actions>
    </service>
    <service verb="put" noun="DataDocumentMappings">
        <in-parameters><parameter name="indexName" required="true"/></in-parameters>
        <actions><script>
            import org.moqui.elasticsearch.EsClient
            EsClient esClient = ec.getTool("ElasticSearch", EsClient.class)
            esClient.putIndexMappings(indexName)
        </script></actions>
    </service>

    <service verb="index" noun="DataFeedDocuments" authenticate="false" transaction-timeout="3600">
        <description>Index all documents associated with the feed within the date range. Recommend calling through the IndexDataFeedDocuments service job.</description>
        <in-parameters>
            <parameter name="dataFeedId" required="true"/>
            <parameter name="fromUpdateStamp" type="Timestamp"/>
            <parameter name="thruUpdateStamp" type="Timestamp"/>
        </in-parameters>
        <out-parameters>
            <parameter name="documentsIndexed" type="Integer"/>
        </out-parameters>
        <actions>
            <set field="startTime" from="System.currentTimeMillis()"/>
            <entity-find entity-name="moqui.entity.feed.DataFeedDocument" list="dfDocList" cache="true">
                <econdition field-name="dataFeedId"/></entity-find>
            <entity-find-one entity-name="moqui.entity.feed.DataFeed" value-field="df" cache="true"/>
            <if condition="df == null"><return type="danger" message="No DataFeed found for ID ${dataFeedId}"/></if>

            <set field="documentsIndexed" from="0"/>
            <script><![CDATA[
                import org.moqui.context.ExecutionContext
                import org.moqui.elasticsearch.EsClient
                import java.util.concurrent.Future

                ExecutionContext ec = context.ec
                EsClient esClient = ec.getTool("ElasticSearch", EsClient.class)
                String feedReceiveServiceName = df.feedReceiveServiceName ?: 'org.moqui.search.SearchServices.index#DataDocuments'

                for (Map dfDoc in dfDocList) {
                    ArrayList<Map> documentList = ec.entity.entityDataDocument.getDataDocuments(dfDoc.dataDocumentId, null, fromUpdateStamp, thruUpdatedStamp)
                    if (!documentList) continue
                    // make sure the index exists
                    esClient.checkCreateIndex((String) documentList.get(0).get("_index"))

                    // index the documents
                    int docListSize = documentList.size()
                    // NOTE: doing multiple threads doesn't make a big difference, the bulk indexing makes a huge difference, so effectively disabling this in the if expression
                    if (false) {
                        int numThreads = Runtime.getRuntime().availableProcessors() / 2
                        ec.logger.info("Indexing ${docListSize} type ${dfDoc.dataDocumentId} documents for feed ${dataFeedId} with ${numThreads} threads")
                        int subListSize = docListSize / numThreads
                        ArrayList<Future> futureList = new ArrayList<>(numThreads)
                        for (int i = 0; i < numThreads - 1; i++) {
                            futureList.add(ec.service.async().name(feedReceiveServiceName)
                                    .parameter("documentList", documentList.subList(i * subListSize, (i + 1) * subListSize))
                                    .parameter("verifyIndexes", false)
                                    .callFuture())
                        }
                        futureList.add(ec.service.async().name(feedReceiveServiceName)
                                .parameter("documentList", documentList.subList((numThreads - 1) * subListSize, docListSize))
                                .parameter("verifyIndexes", false)
                                .callFuture())
                        for (Future future in futureList) future.get()
                    } else {
                        ec.logger.info("Indexing ${docListSize} type ${dfDoc.dataDocumentId} documents for feed ${dataFeedId}")
                        ec.service.sync().name(feedReceiveServiceName).parameter("documentList", documentList).call()
                    }
                    documentsIndexed += documentList.size()
                }
            ]]></script>

            <!-- old simple approach, just one call for all documents in feed:
            <set field="documentList" from="ec.entity.getEntityDataFeed().getFeedDocuments(dataFeedId, fromUpdateStamp, thruUpdatedStamp)"/>
            <set field="feedStamp" from="thruUpdateStamp ?: ec.user.nowTimestamp"/>
            <if condition="documentList">
                <service-call name="org.moqui.search.SearchServices.index#DataDocuments" in-map="context"/>
            </if>
            <set field="documentsIndexed" from="documentList?.size() ?: 0"/>
            -->
            <message>Indexed ${documentsIndexed} documents for feed ${dataFeedId} in ${System.currentTimeMillis() - startTime}ms</message>
        </actions>
    </service>

    <service verb="index" noun="WikiSpacePages">
        <description>Find all pages in space, make sure each has a WikiPage record, and index the page for searching.</description>
        <in-parameters>
            <parameter name="wikiSpaceId"/>
            <parameter name="dataDocumentId" required="true"/>
        </in-parameters>
        <actions>
            <service-call name="org.moqui.impl.WikiServices.get#WikiSpacePages" in-map="[wikiSpaceId:wikiSpaceId]" out-map="context"/>

            <set field="recordsCreated" from="0"/>
            <set field="documentList" from="[]"/>
            <iterate list="allChildFileFlatList" entry="allChildFileFlat">
                <service-call name="org.moqui.impl.WikiServices.get#WikiPageId" out-map="getWpiResult"
                              in-map="[wikiSpaceId:wikiSpaceId, pagePath:allChildFileFlat.path, createIfMissing:true]"/>
                <if condition="getWpiResult.createdRecord"><set field="recordsCreated" from="recordsCreated + 1"/></if>

                <script>documentList.addAll(ec.entity.getDataDocuments(dataDocumentId,
                    ec.entity.conditionFactory.makeCondition([wikiPageId:getWpiResult.wikiPageId]), null, null))</script>
            </iterate>
            <script>ec.service.sync().name("org.moqui.search.SearchServices.index#DataDocuments").parameter("documentList", documentList).call()</script>

            <message>Found and indexed ${allChildFileFlatList.size()} pages in Wiki Space [${wikiSpaceId}], created DB records for ${recordsCreated}.</message>
        </actions>
    </service>

    <service verb="search" noun="DataDocuments">
        <description>
            The queryString format is the ElasticSearch supported one, based on the Lucene query strings which are documented here:

            https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html

            Sort options are described here:

            http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-sort.html
        </description>
        <in-parameters>
            <parameter name="indexName" required="true"/>
            <parameter name="documentType"><description>The ElasticSearch document type. For DataDocument based docs
                this is the dataDocumentId.</description></parameter>
            <parameter name="queryString" required="true"/>
            <parameter name="orderByFields" type="List"><parameter name="orderByField"/></parameter>
            <parameter name="highlightFields" type="List"><parameter name="highlightField"/></parameter>
            <parameter name="pageIndex" type="Integer" default="0"/>
            <parameter name="pageSize" type="Integer" default="20"/>
            <parameter name="flattenDocument" type="Boolean" default="true"/>
        </in-parameters>
        <out-parameters>
            <parameter name="documentList" type="List">
                <description>List of documents, each document is a Map with nested Maps and Lists of Maps.</description>
                <parameter name="document" type="Map"/>
            </parameter>
            <parameter name="documentListCount" type="Integer"><description>The total count of hits, not just the
                limited number returned.</description></parameter>
            <parameter name="documentListPageIndex" type="Integer"/>
            <parameter name="documentListPageSize" type="Integer"/>
            <parameter name="documentListPageMaxIndex" type="Integer"/>
            <parameter name="documentListPageRangeLow" type="Integer"/>
            <parameter name="documentListPageRangeHigh" type="Integer"/>
        </out-parameters>
        <actions><script><![CDATA[
            /* useful docs for query API: http://www.elasticsearch.org/guide/reference/api/search/uri-request/ */

            import org.elasticsearch.action.get.MultiGetItemResponse
            import org.elasticsearch.action.get.MultiGetRequestBuilder
            import org.elasticsearch.action.search.SearchRequest
            import org.elasticsearch.action.search.SearchRequestBuilder
            import org.elasticsearch.index.query.QueryBuilders
            import org.elasticsearch.search.SearchHit
            import org.elasticsearch.search.SearchHits
            import org.elasticsearch.search.fetch.subphase.highlight.HighlightBuilder
            import org.elasticsearch.search.fetch.subphase.highlight.HighlightField
            import org.elasticsearch.search.sort.SortOrder
            import org.moqui.context.ExecutionContext
            import org.moqui.elasticsearch.ElasticSearchUtil
            import org.moqui.elasticsearch.EsClient

            ExecutionContext ec = context.ec
            EsClient esClient = ec.getTool("ElasticSearch", EsClient.class)

            int fromOffset = pageIndex * pageSize
            int sizeLimit = pageSize

            documentList = []
            boolean hasHighlights = highlightFields != null && highlightFields.size() > 0

            // make sure index exists
            if (!esClient.checkIndexExists(indexName)) {
                ec.loggerFacade.warn("Tried to search with indexName ${indexName} that does not exist, returning empty list")
                documentListCount = 0
                documentListPageIndex = pageIndex
                documentListPageSize = pageSize
                documentListPageMaxIndex = 0
                documentListPageRangeLow = 0
                documentListPageRangeHigh = 0
                return
            }

            // get the search hits
            SearchRequest searchRequest = new SearchRequest(indexName)
            searchRequest.source().from(fromOffset).size(sizeLimit).fetchSource(true)
                    .query(QueryBuilders.queryStringQuery((String) queryString).lenient(true).timeZone(TimeZone.default.getID()))
            // SearchRequestBuilder srb = elasticSearchClient.prepareSearch().setIndices(indexName).setFrom(fromOffset).setSize(sizeLimit)
            //         .setQuery(QueryBuilders.queryStringQuery((String) queryString).lenient(true).timeZone(TimeZone.default.getID())).setFetchSource(true)
            if (hasHighlights) {
                HighlightBuilder hb = new HighlightBuilder()
                HashSet<String> fieldSet = new HashSet<>()
                for (String hlField in highlightFields) {
                    if (fieldSet.contains(hlField)) continue
                    fieldSet.add(hlField)
                    hb.field(hlField)
                }
                searchRequest.source().highlighter(hb)
                // srb.highlighter(hb)
            }
            if (documentType) searchRequest.types(((String) documentType).split(","))
            for (String orderByField in orderByFields) {
                orderByField = orderByField.trim()
                boolean ascending = true
                if (orderByField.charAt(0) == '-') {
                    ascending = false
                    orderByField = orderByField.substring(1)
                } else if (orderByField.charAt(0) == '+') {
                    ascending = true
                    orderByField = orderByField.substring(1)
                }
                // ec.logger.warn("========= adding [${orderByField}], ${ascending}; from ${orderByFields}")
                searchRequest.source().sort(orderByField, ascending ? SortOrder.ASC : SortOrder.DESC)
                // srb.addSort(orderByField, ascending ? SortOrder.ASC : SortOrder.DESC)
            }

            SearchHits hits = esClient.search(searchRequest).getHits()
            // SearchHits hits = srb.execute().actionGet().getHits()
            for (SearchHit hit in hits) {
                Map document = hit.getSourceAsMap()
                if (flattenDocument) document = flattenNestedMap(document)

                // As of ES 2.0 _index, _type, _id aren't included in the document
                document._index = hit.getIndex()
                document._type = hit.getType()
                document._id = hit.getId()
                // how to get timestamp? doesn't seem to be in API: document._timestamp = hit.get?
                document._version = hit.getVersion()

                if (hasHighlights) {
                    Map<String, HighlightField> highlightFields = hit.getHighlightFields()
                    Map highlights = [:]
                    for (Map.Entry<String, HighlightField> hlEntry in highlightFields.entrySet())
                        highlights.put(hlEntry.key, Arrays.asList(hlEntry.value.getFragments()))
                    document.put("highlights", highlights)
                    // ec.logger.warn("Highlight Fields: " + highlights)
                }

                documentList.add(document)
            }

            // get the total search count
            documentListCount = hits.getTotalHits()

            // calculate the pagination values
            documentListPageIndex = pageIndex
            documentListPageSize = pageSize
            documentListPageMaxIndex = ((BigDecimal) documentListCount - 1).divide(documentListPageSize, 0, BigDecimal.ROUND_DOWN) as int
            documentListPageRangeLow = documentListPageIndex * documentListPageSize + 1
            documentListPageRangeHigh = (documentListPageIndex * documentListPageSize) + documentListPageSize
            if (documentListPageRangeHigh > documentListCount) documentListPageRangeHigh = documentListCount
        ]]></script></actions>
    </service>
</services>
